{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e08f68",
   "metadata": {},
   "source": [
    "<div style=\"background:#5D6D7E;padding:20px;color:#ffffff;margin-top:10px;\">\n",
    "\n",
    "# NLP - Práctica 2 ( Recuperación de Información) \n",
    "\n",
    "## Profesora: Lisibonny Beato\n",
    "### Período 3-2023-2024</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cebb0323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.463637Z",
     "start_time": "2025-07-03T15:20:10.845787Z"
    }
   },
   "source": [
    "# Importando algunas librerias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.release import author\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from os import path\n",
    "from textblob import TextBlob\n",
    "import xml.etree.ElementTree as ET\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "38cb051e",
   "metadata": {},
   "source": [
    "<div style=\"background:#ff6242;padding:20px;color:#ffffff;margin-top:10px;\">\n",
    "<b>El propósito de esta asignación es que el estudiante ponga en práctica la construcción de sistemas de recuperación de información basado en el modelo clásico de RI Vector Space Model, así como también que evalue la efectividad de estos modelos mediante el uso de una colección de referencia (Benchmark).\n",
    "<br />\n",
    "<br />\n",
    "Para esta práctica estará utilizando el siguiente repositorio:https://github.com/oussbenk/cranfield-trec-dataset. En el mismo encontrarán los archivos  cran.all.1400.xml, cran.qry.xml, cranqrel.trec.txt:\n",
    "<ul>\n",
    "<li>cran.all.1400.xml contiene 1,400 resumenes de artículos científicos.</li>\n",
    "<li>cran.qry.xml 225 términos que representan consultas.</li>\n",
    "<li>cranqrel.trec.txt contiene los juicios de relevancia a dichas consultas.</li>\n",
    "    </ul>  \n",
    "<br />\n",
    "<br />\n",
    "Estudie en detalle la estructura y el contenido de este conjunto de documentos provistos antes de comenzar.    \n",
    "<br />\n",
    "<br />\n",
    "En este trabajo, aparte del código, debe proveer una interpretación para cada tarea y un análisis para cada resultado obtenido que así lo amerite.</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebd3b5",
   "metadata": {},
   "source": [
    "## 1. Ejercicio 1\n",
    "### Puntuación máxima de la tarea: 3 puntos\n",
    "#### Limpieza y preparación de los datos, utilizando distintas técnicas de las ya vistas en clases. Para esta tarea utilizará el archivo cran.all.1400.xml, específicamente sus columnas title y text.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.477438Z",
     "start_time": "2025-07-03T15:20:11.473558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_cranfield_xml(file_path):\n",
    "    \"\"\"\n",
    "    Parse Cranfield XML file by handling the specific format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # The file likely has multiple <DOC> elements without a root wrapper\n",
    "        # Let's wrap the entire content in a root element\n",
    "        wrapped_content = f'<root>\\n{content}\\n</root>'\n",
    "\n",
    "        # Try to parse the wrapped content\n",
    "        root = ET.fromstring(wrapped_content)\n",
    "        return root\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"ParseError: {e}\")\n",
    "        # If that fails, let's try a different approach\n",
    "        return parse_cranfield_alternative(file_path)"
   ],
   "id": "ac2907f8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.494036Z",
     "start_time": "2025-07-03T15:20:11.490413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_cranfield_alternative(file_path):\n",
    "    \"\"\"\n",
    "    Alternative parsing method using regex to extract documents\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Find all DOC elements using regex\n",
    "    doc_pattern = r'<DOC>(.*?)</DOC>'\n",
    "    doc_matches = re.findall(doc_pattern, content, re.DOTALL)\n",
    "\n",
    "    documents = []\n",
    "    for i, doc_content in enumerate(doc_matches):\n",
    "        try:\n",
    "            # Create a proper XML structure for each document\n",
    "            wrapped_doc = f'<DOC>{doc_content}</DOC>'\n",
    "            doc_element = ET.fromstring(wrapped_doc)\n",
    "            documents.append(doc_element)\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Error parsing document {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return documents"
   ],
   "id": "c8a867b8d12095fd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.525104Z",
     "start_time": "2025-07-03T15:20:11.500895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parse the XML file\n",
    "try:\n",
    "    root = parse_cranfield_xml('cranfield-trec-dataset/cran.all.1400.xml')\n",
    "\n",
    "    # Extract data based on the structure we find\n",
    "    data = []\n",
    "\n",
    "    if isinstance(root, list):\n",
    "        # If we got a list from the alternative parser\n",
    "        docs = root\n",
    "    else:\n",
    "        # If we got an ElementTree root\n",
    "        docs = root.findall('.//DOC')\n",
    "\n",
    "    print(f\"Found {len(docs)} documents\")\n",
    "\n",
    "    for doc in docs:\n",
    "        docno = doc.find('DOCNO').text.strip() if doc.find(\n",
    "            'DOCNO') is not None else ''\n",
    "        title = doc.find('TITLE').text.strip() if doc.find(\n",
    "            'TITLE') is not None else ''\n",
    "        author_elem = doc.find('AUTHOR')\n",
    "        author = author_elem.text.strip() if author_elem is not None and author_elem.text else ''\n",
    "        bib_elem = doc.find('BIB')\n",
    "        bib = bib_elem.text.strip() if bib_elem is not None and bib_elem.text else ''\n",
    "        text_elem = doc.find('TEXT')\n",
    "        text = text_elem.text.strip() if text_elem is not None and text_elem.text else ''\n",
    "\n",
    "        data.append({\n",
    "            'docno': docno,\n",
    "            'title': title,\n",
    "            'author': author,\n",
    "            'bib': bib,\n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "    # Convert the data to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Created DataFrame with {len(df)} rows\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Show first few rows to verify\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df[['docno', 'title']].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Let's examine the file structure more carefully...\")\n",
    "\n",
    "    # Fallback: examine the file structure\n",
    "    with open('cranfield-trec-dataset/cran.all.1400.xml', 'r',\n",
    "              encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    print(f\"File has {len(lines)} lines\")\n",
    "    print(\"First 20 lines:\")\n",
    "    for i, line in enumerate(lines[:20]):\n",
    "        print(f\"{i + 1:2d}: {line.rstrip()}\")"
   ],
   "id": "23dd537f22193b34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 documents\n",
      "Created DataFrame with 0 rows\n",
      "Columns: []\n",
      "\n",
      "First 5 rows:\n",
      "Error: \"None of [Index(['docno', 'title'], dtype='object')] are in the [columns]\"\n",
      "Let's examine the file structure more carefully...\n",
      "File has 36734 lines\n",
      "First 20 lines:\n",
      " 1: <doc>\n",
      " 2: <docno>1</docno>\n",
      " 3: <title>experimental investigation of the aerodynamics of a\n",
      " 4: wing in a slipstream .</title>\n",
      " 5: <author>brenckman,m.</author>\n",
      " 6: <bib>j. ae. scs. 25, 1958, 324.</bib>\n",
      " 7: <text>experimental investigation of the aerodynamics of a\n",
      " 8: wing in a slipstream .\n",
      " 9:   an experimental study of a wing in a propeller slipstream was\n",
      "10: made in order to determine the spanwise distribution of the lift\n",
      "11: increase due to slipstream at different angles of attack of the wing\n",
      "12: and at different free stream to slipstream velocity ratios .  the\n",
      "13: results were intended in part as an evaluation basis for different\n",
      "14: theoretical treatments of this problem .\n",
      "15:   the comparative span loading curves, together with\n",
      "16: supporting evidence, showed that a substantial part of the lift increment\n",
      "17: produced by the slipstream was due to a /destalling/ or\n",
      "18: boundary-layer-control effect .  the integrated remaining lift\n",
      "19: increment, after subtracting this destalling lift, was found to agree\n",
      "20: well with a potential flow theory .\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1f70b865",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFE0;padding:20px;color:#000000;margin-top:10px;\">\n",
    "Utilice esta celda para colocar comentarios en el notebook, cuando lo estime necesario. Copiela varias veces donde considere.\n",
    "</div>"
   ]
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    },
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.538911Z",
     "start_time": "2025-07-03T15:20:11.536715Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": "%%sql\n",
   "id": "1cef42afc2e3a8ce",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "36d2ba20",
   "metadata": {},
   "source": [
    "## 2. Ejercicio 2\n",
    "### Puntuación máxima de la tarea: 2 puntos\n",
    "#### Construir al menos dos modelos de recuperación de información basado en el modelo vectorial, visto en detalle en clases, cada uno con una configuración distinta de textos, tal y como se indica a continuación: solo title y title+text."
   ]
  },
  {
   "cell_type": "code",
   "id": "44dc13eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T15:20:11.544584Z",
     "start_time": "2025-07-03T15:20:11.542573Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d803e21",
   "metadata": {},
   "source": [
    "## 3. Ejercicio 3\n",
    "### Puntuación máxima de la tarea: 5 puntos\n",
    "#### Evaluar los modelos de recuperación de información construidos, mediante la  utilización de la colección de referencia dada (Archivos cran.qry.xml y cranqrel.trec.txt  ).  Seleccione dos métricas ampliamente utilizadas en la evaluación de este tipo de sistemas y analice los resultados para determinar cual es el mejor de los modelos. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec06e60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
